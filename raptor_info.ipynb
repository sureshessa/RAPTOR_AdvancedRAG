{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval-augmented language models can better adapt to changes in world state and incorporate long-tail knowledge. \n",
    "\n",
    "However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, limiting holistic under- standing of the overall document context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAPTOR Approach:\n",
    "\n",
    "- The leafs are a set of starting documents\n",
    "- Leafs are embedded and clustered\n",
    "- Clusters are then summarized into higher level (more abstract) consolidations of information across similar documents\n",
    "\n",
    "- RAPTOR approach is recursively embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization from the bottom up. \n",
    "\n",
    "- At inference time, RAPTOR model retrieves from this tree, \n",
    "integrating information across lengthy documents at different levels of abstraction\n",
    "\n",
    "- To group similar text chunks, we can use clustering algorithm. Once clustered, a Language Model is used to summarize the grouped texts. \n",
    "\n",
    "- These summarized texts are then re-embedded, and the cycle of embedding, clustering, and summarization continues until further clustering becomes infeasible, resulting in a structured, multi-layered tree representation of the original documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Algorithm\n",
    "\n",
    "- Clustering plays a key role in building the RAPTOR tree, organizing text segments into cohesive groups. \n",
    "- This step groups related content together, which helps the subse- quent retrieval process.\n",
    "- We can use clustering algorithm is based on Gaussian Mixture Models (GMMs), an approach that offers both flexibility and a probabilistic framework. \n",
    "- GMMs assume that data points are generated from a mixture of several Gaussian distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP (dimensionality reduction technique)\n",
    "\n",
    "- The high dimensionality of vector embeddings presents a challenge for traditional GMMs, as dis- tance metrics may behave poorly when used to measure similarity in high-dimensional spaces. \n",
    "\n",
    "- To mitigate this, we can use Uniform Manifold Approximation and Projection (UMAP), a manifold learning technique for dimensionality reduction. \n",
    "\n",
    "- The number of nearest neighbors parameter, n neighbors, in UMAP determines the balance between the preservation of local and global structures, algorithm varies n neighbors to create a hierar- chical clustering structure\n",
    "\n",
    "- it first identifies global clusters and then performs local clustering within these global clusters. \n",
    "\n",
    "- This two-step clustering process captures a broad spectrum of relationships among the text data, from broad themes to specific details.\n",
    "\n",
    "- Should a local cluster’s combined context ever exceed the summarization model’s token threshold, our algorithm recursively applies clustering within the cluster, ensuring that the context remains within the token threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Based Summarization\n",
    "\n",
    "- After clustering the nodes using Gaussian Mixture Models, the nodes in each cluster are sent to a language model for summarization. \n",
    "\n",
    "- This step allows the model to transform large chunks of text into concise, coherent summaries of the selected nodes. we can use llms to generate the summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying:\n",
    "\n",
    "- Two querying mechanisms employed by RAPTOR: tree traversal and collapsed tree. These methods offer unique ways of traversing the multi-layered RAPTOR tree to retrieve relevant information\n",
    "\n",
    "Tree traversal:\n",
    "\n",
    "- Tree traversal starts at the root level of the tree and retrieves the top-k (say, top-1) node(s) based on cosine similarity to the query vector. \n",
    "\n",
    "- At each level, it retrieves the top-k node(s) from the child nodes of the previous layer’s top-k.\n",
    "\n",
    "Collapsed tree:\n",
    "\n",
    "- Collapsed tree it collapses the tree into a single layer and retrieves nodes until a threshold number of tokens is reached, based on cosine similarity to the query vector.\n",
    "\n",
    "- collapsed tree retrieval is better due to offering greater flexibility than tree traversal; i.e., by searching through all the nodes simultaneously, it retrieves information that is at the correct level of granularity for a given question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvRaptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
